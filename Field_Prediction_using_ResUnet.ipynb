{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Field Prediction using ResUnet",
      "provenance": [],
      "authorship_tag": "ABX9TyN9z9sK0JSDXUBr5rXI93tW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asahazmy/Field-prediction/blob/master/Field_Prediction_using_ResUnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQ6cyF_JqEJG",
        "colab_type": "text"
      },
      "source": [
        "Field prediction using ResUnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL64rrCbpun1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a98158a5-7f4c-45f4-a47e-f21933b99f89"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMU1hz7XrOh6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import reduce_sum\n",
        "from tensorflow.keras.backend import pow\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, UpSampling2D, Concatenate, Add, Flatten\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzJt8QSVxptY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c0a8dca5-653a-4629-f6dc-f038d6923989"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vmzMXzrsr0y",
        "colab_type": "text"
      },
      "source": [
        "Configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_ICVSc8suYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Kernel Configurations\n",
        "save_model = True # save the model after training\n",
        "train_dir = '' # directory of training images\n",
        "pretrained_model_path = '' # path of pretrained model\n",
        "model_save_path = '' # path of model to save\n",
        "\n",
        "# original image is 1600x256, so we will resize it\n",
        "img_w = 800 # resized weidth\n",
        "img_h = 256 # resized height\n",
        "epochs = 25\n",
        "# batch size for training unet\n",
        "k_size = 3 # kernel size 3x3\n",
        "val_size = .20 # split of training set between train and validation set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSpZXXrFsxM2",
        "colab_type": "text"
      },
      "source": [
        "Input Data & Mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bHlTljt72L7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "ea347c58-49da-4364-b303-6ea33ec0c524"
      },
      "source": [
        "!git clone https://github.com/asahazmy/Field-prediction.git"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Field-prediction'...\n",
            "remote: Enumerating objects: 123, done.\u001b[K\n",
            "remote: Total 123 (delta 0), reused 0 (delta 0), pack-reused 123\u001b[K\n",
            "Receiving objects: 100% (123/123), 5.28 MiB | 1.56 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGoZkf738JVU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "feb0aefb-c107-4a8d-b294-a732ac2c94d5"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Field-prediction  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OwAg5YOp68c_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pathlib\n",
        "dataset_url = \"https://github.com/asahazmy/Field-prediction.git\"\n",
        "data_dir = tf.keras.utils.get_file(origin=dataset_url, \n",
        "                                   fname='Field-prediction', \n",
        "                                   untar=True)\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qgj9yrBo7FP7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7ca69459-1006-4f6e-b26c-9edf881f7468"
      },
      "source": [
        "image_count = len(list(data_dir.glob('dataset/image/img.png')))\n",
        "print(image_count)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGdY_ylEs2WB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "path_img = 'dataset\\image'\n",
        "path_mask = 'dataset\\segmentation_mask'\n",
        "\n",
        "seed = 1000 # (IMPORTANT) to transform image and corresponding mask with same augmentation parameter.\n",
        "image_datagen = ImageDataGenerator(width_shift_range=0.1,\n",
        "                 height_shift_range=0.1,\n",
        "                 preprocessing_function = image_preprocessing) # custom fuction for each image you can use resnet one too.\n",
        "mask_datagen = ImageDataGenerator(width_shift_range=0.1,\n",
        "                 height_shift_range=0.1,\n",
        "                 preprocessing_function = mask_preprocessing)  # to make mask as feedable formate (256,256,1)\n",
        "\n",
        "image_generator =image_datagen.flow_from_directory(path_img,\n",
        "                                                    class_mode=None, seed=seed)\n",
        "\n",
        "mask_generator = mask_datagen.flow_from_directory(path_mask,\n",
        "                                                   class_mode=None, seed=seed)\n",
        "\n",
        "train_generator = zip(image_generator, mask_generator)\n",
        "\n",
        "\n",
        "#Normalisasi data\n",
        "def normalize(input_image, input_mask):\n",
        "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "  input_mask -= 1\n",
        "  return input_image, input_mask\n",
        "\n",
        "#input data\n",
        "def load_image_train(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (256, 256))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (256, 256))\n",
        "\n",
        "  if tf.random.uniform(()) > 0.5:\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    input_mask = tf.image.flip_left_right(input_mask)\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask\n",
        "\n",
        "def load_image_test(datapoint):\n",
        "  input_image = tf.image.resize(datapoint['image'], (256, 256))\n",
        "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (256, 256))\n",
        "\n",
        "  input_image, input_mask = normalize(input_image, input_mask)\n",
        "\n",
        "  return input_image, input_mask\n",
        "\n",
        "train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test = dataset['test'].map(load_image_test)\n",
        "\n",
        "TRAIN_LENGTH = info.splits['train'].num_examples\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
        "\n",
        "\n",
        "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test.batch(BATCH_SIZE)\n",
        "\n",
        "#checking the data\n",
        "def display(display_list):\n",
        "  plt.figure(figsize=(15, 15))\n",
        "\n",
        "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "\n",
        "  for i in range(len(display_list)):\n",
        "    plt.subplot(1, len(display_list), i+1)\n",
        "    plt.title(title[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "for image, mask in train.take(1):\n",
        "  sample_image, sample_mask = image, mask\n",
        "display([sample_image, sample_mask])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDxwzHGKs_SL",
        "colab_type": "text"
      },
      "source": [
        "Model Architecture (ResUnet)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdW3JCCLtWUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bn_act(x, act=True):\n",
        "    'batch normalization layer with an optinal activation layer'\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    if act == True:\n",
        "        x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x\n",
        "def conv_block(x, filters, kernel_size=3, padding='same', strides=1):\n",
        "    'convolutional layer which always uses the batch normalization layer'\n",
        "    conv = bn_act(x)\n",
        "    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(conv)\n",
        "    return conv\n",
        "def stem(x, filters, kernel_size=3, padding='same', strides=1):\n",
        "    conv = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    conv = conv_block(conv, filters, kernel_size, padding, strides)\n",
        "    shortcut = Conv2D(filters, kernel_size=1, padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "    output = Add()([conv, shortcut])\n",
        "    return output\n",
        "def residual_block(x, filters, kernel_size=3, padding='same', strides=1):\n",
        "    res = conv_block(x, filters, k_size, padding, strides)\n",
        "    res = conv_block(res, filters, k_size, padding, 1)\n",
        "    shortcut = Conv2D(filters, kernel_size, padding=padding, strides=strides)(x)\n",
        "    shortcut = bn_act(shortcut, act=False)\n",
        "    output = Add()([shortcut, res])\n",
        "    return output\n",
        "def upsample_concat_block(x, xskip):\n",
        "    u = UpSampling2D((2,2))(x)\n",
        "    c = Concatenate()([u, xskip])\n",
        "    return c\n",
        "\n",
        "\n",
        "def ResUNet(img_h, img_w):\n",
        "    f = [16, 32, 64, 128, 256]\n",
        "    inputs = Input((img_h, img_w, 1))\n",
        "\n",
        "    ## Encoder\n",
        "    e0 = inputs\n",
        "    e1 = stem(e0, f[0])\n",
        "    e2 = residual_block(e1, f[1], strides=2)\n",
        "    e3 = residual_block(e2, f[2], strides=2)\n",
        "    e4 = residual_block(e3, f[3], strides=2)\n",
        "    e5 = residual_block(e4, f[4], strides=2)\n",
        "\n",
        "    ## Bridge\n",
        "    b0 = conv_block(e5, f[4], strides=1)\n",
        "    b1 = conv_block(b0, f[4], strides=1)\n",
        "\n",
        "    ## Decoder\n",
        "    u1 = upsample_concat_block(b1, e4)\n",
        "    d1 = residual_block(u1, f[4])\n",
        "\n",
        "    u2 = upsample_concat_block(d1, e3)\n",
        "    d2 = residual_block(u2, f[3])\n",
        "\n",
        "    u3 = upsample_concat_block(d2, e2)\n",
        "    d3 = residual_block(u3, f[2])\n",
        "\n",
        "    u4 = upsample_concat_block(d3, e1)\n",
        "    d4 = residual_block(u4, f[1])\n",
        "\n",
        "    outputs = tf.keras.layers.Conv2D(4, (1, 1), padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "    model = tf.keras.models.Model(inputs, outputs)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aj7SmDlCtang",
        "colab_type": "text"
      },
      "source": [
        "Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLKj5ioqtckg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dsc(y_true, y_pred):\n",
        "    smooth = 1.\n",
        "    y_true_f = Flatten()(y_true)\n",
        "    y_pred_f = Flatten()(y_pred)\n",
        "    intersection = reduce_sum(y_true_f * y_pred_f)\n",
        "    score = (2. * intersection + smooth) / (reduce_sum(y_true_f) + reduce_sum(y_pred_f) + smooth)\n",
        "    return score\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    loss = 1 - dsc(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    loss = binary_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
        "    return loss\n",
        "\n",
        "# Focal Tversky loss, brought to you by:  https://github.com/nabsabraham/focal-tversky-unet\n",
        "def tversky(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_pos = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred_pos = tf.keras.layers.Flatten()(y_pred)\n",
        "    true_pos = tf.reduce_sum(y_true_pos * y_pred_pos)\n",
        "    false_neg = tf.reduce_sum(y_true_pos * (1-y_pred_pos))\n",
        "    false_pos = tf.reduce_sum((1-y_true_pos)*y_pred_pos)\n",
        "    alpha = 0.7\n",
        "    return (true_pos + smooth)/(true_pos + alpha*false_neg + (1-alpha)*false_pos + smooth)\n",
        "\n",
        "def tversky_loss(y_true, y_pred):\n",
        "    return 1 - tversky(y_true,y_pred)\n",
        "\n",
        "def focal_tversky_loss(y_true,y_pred):\n",
        "    pt_1 = tversky(y_true, y_pred)\n",
        "    gamma = 0.75\n",
        "    return tf.keras.backend.pow((1-pt_1), gamma)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjAXwPaxthzv",
        "colab_type": "text"
      },
      "source": [
        "Compile & Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7luAJxK7tm-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ResUNet(img_h=img_h, img_w=img_w)\n",
        "adam = tf.keras.optimizers.Adam(lr = 0.05, epsilon = 0.1)\n",
        "model.compile(optimizer=adam, loss=focal_tversky_loss, metrics=[tversky])\n",
        "\n",
        "if load_pretrained_model:\n",
        "    try:\n",
        "        model.load_weights(pretrained_model_path)\n",
        "        print('pre-trained model loaded!')\n",
        "    except OSError:\n",
        "        print('You need to run the model and load the trained model')\n",
        "\n",
        "#history = model.fit_generator(generator=training_generator, validation_data=validation_generator, epochs=epochs, verbose=1)\n",
        "\n",
        "if save_model:\n",
        "    model.save(model_save_path)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}